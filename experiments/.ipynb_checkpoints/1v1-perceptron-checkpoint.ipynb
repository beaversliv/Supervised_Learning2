{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "\n",
    "We import our code and any frequently used libraries, and set up our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/zipcombo.dat'\n",
    "SRC_PATH = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(SRC_PATH))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.kernels import polynomial_kernel\n",
    "from src.perceptrons import VectorizedOneVsOneKernelPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, sep=' ', header=None).drop(columns=[257])\n",
    "df.rename(columns={0: 'label'}, inplace=True)\n",
    "X = df[list(range(1, 257))].values\n",
    "y = df['label'].values.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not currently use subsampling, but we keep the function for testing purposes\n",
    "\n",
    "def subsample(df, classes, sample_size=100):\n",
    "    # sampling\n",
    "    df_small = pd.DataFrame()\n",
    "    for clazz in classes:\n",
    "        df_clazz = df[df['y'] == clazz]\n",
    "        df_sample = df_clazz.sample(sample_size)\n",
    "        df_small = df_small.append(df_sample)\n",
    "\n",
    "    #shuffle\n",
    "    df_small = df_small.sample(frac=1.)\n",
    "\n",
    "    X_small = df_small.drop(columns='y').values\n",
    "    y_small = df_small['y'].values\n",
    "    \n",
    "    return X_small, y_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df['y'] = y\n",
    "X, y = subsample(df, list(range(10)), sample_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def error_score(y, y_pred):\n",
    "    return 1 - accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic Results\n",
    "We split our data into 80%/20% train and test. We perform 20 runs for $d = 1, ..., 7$, and report the mean test and training errors with their standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define basic run for part 1.1\n",
    "\n",
    "def basic_run(X_train, X_test, y_train, y_test, kernel, epochs=2, progress=False):    \n",
    "    #fit model\n",
    "    mkp = VectorizedOneVsOneKernelPerceptron(X_train, y_train, kernel)\n",
    "    mkp.train_for_epochs(epochs, progress=progress)\n",
    "    \n",
    "    #return errors\n",
    "    error_train = error_score(y_train, mkp.predict_all(X_train))\n",
    "    error_test = error_score(y_test, mkp.predict_all(X_test))\n",
    "    \n",
    "    return {'err_train': error_train, 'err_test': error_test, 'model': mkp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:19<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# perform basic runs\n",
    "iterations = 20\n",
    "ds = list(range(1, 8))\n",
    "err_train = {d: [] for d in ds}\n",
    "err_test = {d: [] for d in ds}\n",
    "\n",
    "for iteration in tqdm(list(range(iterations))):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)\n",
    "    \n",
    "    for d in ds:\n",
    "        #split data\n",
    "        results = basic_run(X_train, X_test, y_train, y_test, polynomial_kernel(d), 5)\n",
    "        err_train[d].append(results['err_train'])\n",
    "        err_test[d].append(results['err_test'])\n",
    "    \n",
    "err_train_mean = {d: np.mean(errs) for d, errs in err_train.items()}\n",
    "err_test_mean = {d: np.mean(errs) for d, errs in err_test.items()}\n",
    "err_train_std = {d: np.std(errs) for d, errs in err_train.items()}\n",
    "err_test_std = {d: np.std(errs) for d, errs in err_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.035843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.033597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.032600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_mean  test_mean  train_std  test_std\n",
       "1    0.017375     0.1445   0.010015  0.035843\n",
       "2    0.003250     0.1475   0.008518  0.033597\n",
       "3    0.001375     0.1385   0.003209  0.032600\n",
       "4    0.000000     0.1445   0.000000  0.025976\n",
       "5    0.000000     0.1475   0.000000  0.030475\n",
       "6    0.000000     0.1510   0.000000  0.029138\n",
       "7    0.000000     0.1475   0.000000  0.020946"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display in dataframe\n",
    "df_err = pd.DataFrame([err_train_mean, err_test_mean,\n",
    "                       err_train_std, err_test_std], \n",
    "                       index=['train_mean', 'test_mean', 'train_std', 'test_std'], \n",
    "                       columns=ds).T\n",
    "df_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cross-validation\n",
    "\n",
    "We split our data into 80%/20% train and test. We then use 5-fold cross validation to find our best $d^*$ parameter for $d^* \\in \\{1, ..., 7\\}$. We then retrain our optimal kernelised perceptron on the full training set, and calculate training and test errors over 20 runs. We report the mean test and training errors for this perceptron, as well as its standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fold_indices(n, k=5):\n",
    "    ixs = np.array(range(n))\n",
    "    np.random.shuffle(ixs)\n",
    "    folds = np.array_split(ixs, k)\n",
    "    fold_ixs = np.zeros(n)\n",
    "    for i in range(k):\n",
    "        fold_ixs[folds[i]] = i\n",
    "    return fold_ixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate k folds and perform cross-validation on them, returning error per fold.\n",
    "def cross_validation_error(X, y, kernel, epochs=2, k=5):\n",
    "    fold_ixs = make_fold_indices(len(X), k=k)\n",
    "\n",
    "    cv_errs = []\n",
    "    for fold_ix in np.unique(fold_ixs):\n",
    "        X_val = X[fold_ixs == fold_ix]\n",
    "        y_val = y[fold_ixs == fold_ix]\n",
    "        X_train = X[fold_ixs != fold_ix]\n",
    "        y_train = y[fold_ixs != fold_ix]\n",
    "        \n",
    "        #fit model\n",
    "        mkp = VectorizedOneVsOneKernelPerceptron(X_train, y_train, kernel)\n",
    "        mkp.train_for_epochs(epochs=5)\n",
    "        \n",
    "        #record validation fold error\n",
    "        mkp.train_for_epochs(epochs)\n",
    "        cv_errs.append(error_score(y_val, mkp.predict_all(X_val)))\n",
    "        \n",
    "    return np.mean(cv_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\n",
      "  5%|████                                                                            | 1/20 [12:21<3:54:50, 741.62s/it]\n",
      " 10%|████████                                                                        | 2/20 [24:43<3:42:27, 741.55s/it]\n",
      " 15%|████████████                                                                    | 3/20 [37:11<3:30:41, 743.60s/it]\n",
      " 20%|████████████████                                                                | 4/20 [49:41<3:18:48, 745.55s/it]\n",
      " 25%|███████████████████▌                                                          | 5/20 [1:02:07<3:06:27, 745.81s/it]\n",
      " 30%|███████████████████████▍                                                      | 6/20 [1:14:30<2:53:49, 744.96s/it]\n",
      " 35%|███████████████████████████▎                                                  | 7/20 [1:27:10<2:42:20, 749.30s/it]\n",
      " 40%|███████████████████████████████▏                                              | 8/20 [1:39:34<2:29:33, 747.78s/it]\n",
      " 45%|███████████████████████████████████                                           | 9/20 [1:52:02<2:17:06, 747.88s/it]\n",
      " 50%|██████████████████████████████████████▌                                      | 10/20 [2:04:56<2:05:57, 755.71s/it]\n",
      " 55%|██████████████████████████████████████████▎                                  | 11/20 [2:17:26<1:53:05, 753.90s/it]\n",
      " 60%|██████████████████████████████████████████████▏                              | 12/20 [2:29:56<1:40:21, 752.67s/it]\n",
      " 65%|██████████████████████████████████████████████████                           | 13/20 [2:42:26<1:27:43, 751.93s/it]\n",
      " 70%|█████████████████████████████████████████████████████▉                       | 14/20 [2:54:57<1:15:10, 751.72s/it]\n",
      " 75%|█████████████████████████████████████████████████████████▊                   | 15/20 [3:07:26<1:02:34, 750.84s/it]\n",
      " 80%|███████████████████████████████████████████████████████████████▏               | 16/20 [3:19:53<49:59, 749.85s/it]\n",
      " 85%|███████████████████████████████████████████████████████████████████▏           | 17/20 [3:32:20<37:26, 748.98s/it]\n",
      " 90%|███████████████████████████████████████████████████████████████████████        | 18/20 [3:44:47<24:56, 748.28s/it]\n",
      " 95%|███████████████████████████████████████████████████████████████████████████    | 19/20 [3:57:19<12:29, 749.25s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 20/20 [4:09:45<00:00, 748.34s/it]"
     ]
    }
   ],
   "source": [
    "# perform cross-validation runs\n",
    "\n",
    "iterations = 20\n",
    "ds = list(range(1, 8))\n",
    "errs_cv = {}\n",
    "\n",
    "d_stars = []\n",
    "errs_test = []\n",
    "for iteration in tqdm(list(range(iterations))):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)\n",
    "    \n",
    "    # perform cross validations\n",
    "    for d in ds:\n",
    "        errs_cv[d] = cross_validation_error(X_train, y_train, polynomial_kernel(d), epochs=10)\n",
    "        \n",
    "    # get best parameter\n",
    "    d_star = min(errs_cv, key=errs_cv.get)\n",
    "    d_stars.append(d_star)\n",
    "    \n",
    "    # get final error\n",
    "    results = basic_run(X_train, X_test, y_train, y_test, polynomial_kernel(d_star), epochs=10)\n",
    "    errs_test.append(results['err_test'])\n",
    "\n",
    "    \n",
    "# compute results   \n",
    "err_test_mean = np.mean(errs_test)\n",
    "d_star_mean = np.mean(d_stars)\n",
    "err_test_std = np.std(errs_test)\n",
    "d_star_std = np.std(d_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_stars</th>\n",
       "      <th>test_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.031183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.035484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.030645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.037634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.039247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0.035484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.039247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.039785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>0.032796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>0.026344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0.031720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>0.030645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>0.036022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0.041935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0.031183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0.032796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0.028495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    d_stars  test_errors\n",
       "0         3     0.031183\n",
       "1         2     0.035484\n",
       "2         4     0.030645\n",
       "3         3     0.030108\n",
       "4         5     0.032258\n",
       "5         6     0.037634\n",
       "6         3     0.039247\n",
       "7         4     0.035484\n",
       "8         4     0.039247\n",
       "9         4     0.039785\n",
       "10        4     0.032796\n",
       "11        3     0.032258\n",
       "12        4     0.026344\n",
       "13        4     0.031720\n",
       "14        5     0.030645\n",
       "15        4     0.036022\n",
       "16        2     0.041935\n",
       "17        4     0.031183\n",
       "18        4     0.032796\n",
       "19        4     0.028495"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_data = {'d_stars': d_stars, 'test_errors': errs_test}\n",
    "df = pd.DataFrame(data=cv_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_test</th>\n",
       "      <th>d_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.033763</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.927362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      err_test    d_star\n",
       "mean  0.033763  3.800000\n",
       "std   0.004054  0.927362"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display in dataframe\n",
    "df_err = pd.DataFrame([[err_test_mean, err_test_std],\n",
    "                       [d_star_mean, d_star_std]], \n",
    "                       columns=['mean', 'std'], index=['err_test', 'd_star']).T\n",
    "print(\"Answer to 2:\")\n",
    "df_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
