{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "\n",
    "We import our code and any frequently used libraries, and set up our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "    \n",
    "DATA_PATH = '../data/zipcombo.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.kernels import polynomial_kernel\n",
    "from src.kernels import gaussian_kernel_2\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from src.perceptrons import VectorizedOneVsAllKernelPerceptron\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Let's initially work with a smaller dataset until we sort out inner and outer efficiency issues (i.e. using one-vs-all and making the individual perceptrons more efficient) <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, sep=' ', header=None).drop(columns=[257])\n",
    "df.rename(columns={0: 'label'}, inplace=True)\n",
    "X = df[list(range(1, 257))].values\n",
    "y = df['label'].values.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not currently use subsampling, but we do still need the function for testing purposes\n",
    "\n",
    "def subsample(df, classes, sample_size=100):\n",
    "    # sampling\n",
    "    df_small = pd.DataFrame()\n",
    "    for clazz in classes:\n",
    "        df_clazz = df[df['y'] == clazz]\n",
    "        df_sample = df_clazz.sample(sample_size)\n",
    "        df_small = df_small.append(df_sample)\n",
    "\n",
    "    #shuffle\n",
    "    df_small = df_small.sample(frac=1.)\n",
    "\n",
    "    X_small = df_small.drop(columns='y').values\n",
    "    y_small = df_small['y'].values\n",
    "    \n",
    "    return X_small, y_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df['y'] = y\n",
    "X, y = subsample(df, list(range(10)), sample_size=100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for creating confusion error matrix\n",
    "\n",
    "def conf_mat(X, y, model):\n",
    "    cats = 10\n",
    "    con_mat = np.zeros((cats,cats))\n",
    "    x_pred = model.predict_all(X)\n",
    "    for i in range(len(y)):\n",
    "        con_mat[y[i], x_pred[i]] += 1\n",
    "    return con_mat\n",
    "\n",
    "def confusion_error(X, y, model):\n",
    "    cats = 10\n",
    "    con_mat = np.zeros((cats,cats))\n",
    "    x_pred = model.predict_all(X)\n",
    "    for i in range(len(y)):\n",
    "        con_mat[y[i], x_pred[i]] += 1\n",
    "\n",
    "        \n",
    "    # row normalize\n",
    "    for j in range(0,cats):\n",
    "        list_i = list(range(0,cats))\n",
    "        list_i.remove(j)\n",
    "        tot = sum(con_mat[j, :]) - con_mat[j,j]\n",
    "        for col in list_i:\n",
    "            if con_mat[j, col] != 0:\n",
    "                con_mat[j, col] = (con_mat[j, col]/tot)*100\n",
    "        con_mat[j, j] = 0\n",
    "    return con_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def error_score(y, y_pred):\n",
    "    return 1 - accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic Results\n",
    "We split our data into 80%/20% train and test. We perform 20 runs for $d = 1, ..., 7$, and report the mean test and training errors with their standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define basic run for part 1.1\n",
    "\n",
    "def basic_run(X_train, X_test, y_train, y_test, kernel, epochs=2, progress=False):    \n",
    "    #fit model\n",
    "    mkp = VectorizedOneVsAllKernelPerceptron(X_train, y_train, kernel)\n",
    "    mkp.train_for_epochs(epochs, progress=progress)\n",
    "    \n",
    "    #return errors\n",
    "    error_train = error_score(y_train, mkp.predict_all(X_train))\n",
    "    error_test = error_score(y_test, mkp.predict_all(X_test))\n",
    "    \n",
    "    return {'err_train': error_train, 'err_test': error_test, 'model': mkp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:46<00:00, 26.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# perform basic runs\n",
    "iterations = 4\n",
    "ds = list(range(1, 5))\n",
    "err_train = {d: [] for d in ds}\n",
    "err_test = {d: [] for d in ds}\n",
    "\n",
    "for iteration in tqdm(list(range(iterations))):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)\n",
    "    \n",
    "    for d in ds:\n",
    "        #split data\n",
    "        results = basic_run(X_train, X_test, y_train, y_test, polynomial_kernel(d), 10)\n",
    "        err_train[d].append(results['err_train'])\n",
    "        err_test[d].append(results['err_test'])\n",
    "    \n",
    "err_train_mean = {d: np.mean(errs) for d, errs in err_train.items()}\n",
    "err_test_mean = {d: np.mean(errs) for d, errs in err_test.items()}\n",
    "err_train_std = {d: np.std(errs) for d, errs in err_train.items()}\n",
    "err_test_std = {d: np.std(errs) for d, errs in err_test.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cross-validation\n",
    "\n",
    "We split our data into 80%/20% train and test. We then use 5-fold cross validation to find our best $d^*$ parameter for $d^* \\in \\{1, ..., 7\\}$. We then retrain our optimal kernelised perceptron on the full training set, and calculate training and test errors over 20 runs. We report the mean test and training errors for this perceptron, as well as its standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fold_indices(n, k=5):\n",
    "    ixs = np.array(range(n))\n",
    "    np.random.shuffle(ixs)\n",
    "    folds = np.array_split(ixs, k)\n",
    "    fold_ixs = np.zeros(n)\n",
    "    for i in range(k):\n",
    "        fold_ixs[folds[i]] = i\n",
    "    return fold_ixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate k folds and perform cross-validation on them, returning error per fold.\n",
    "def cross_validation_error(X, y, kernel, epochs=5, k=5):\n",
    "    fold_ixs = make_fold_indices(len(X), k=k)\n",
    "\n",
    "    cv_errs = []\n",
    "    for fold_ix in np.unique(fold_ixs):\n",
    "        X_val = X[fold_ixs == fold_ix]\n",
    "        y_val = y[fold_ixs == fold_ix]\n",
    "        X_train = X[fold_ixs != fold_ix]\n",
    "        y_train = y[fold_ixs != fold_ix]\n",
    "        \n",
    "        #fit model\n",
    "        mkp = VectorizedOneVsAllKernelPerceptron(X_train, y_train, kernel)\n",
    "        mkp.train_for_epochs(epochs=5)\n",
    "        \n",
    "        #record validation fold error\n",
    "        cv_errs.append(error_score(y_val, mkp.predict_all(X_val)))\n",
    "        \n",
    "    return np.mean(cv_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:11<01:04,  3.78s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-5be8f7205f8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# perform cross validations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0merrs_cv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolynomial_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# get best parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-d0af96d0cafc>\u001b[0m in \u001b[0;36mcross_validation_error\u001b[1;34m(X, y, kernel, epochs, k)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmkp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVectorizedOneVsAllKernelPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmkp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_for_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#record validation fold error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\UCL\\Supervised Learning\\Coursework\\Coursework 2\\supervised-learning-coursework-2\\src\\perceptrons.py\u001b[0m in \u001b[0;36mtrain_for_epochs\u001b[1;34m(self, epochs, progress)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_for_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\UCL\\Supervised Learning\\Coursework\\Coursework 2\\supervised-learning-coursework-2\\src\\perceptrons.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;31m# generate predctions for all perceptrons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_training_pt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m             \u001b[0mincorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_actual\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\UCL\\Supervised Learning\\Coursework\\Coursework 2\\supervised-learning-coursework-2\\src\\perceptrons.py\u001b[0m in \u001b[0;36mpredict_training_pt\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_training_pt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mK_xt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0my_prime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_xt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_prime\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\UCL\\Supervised Learning\\Coursework\\Coursework 2\\supervised-learning-coursework-2\\src\\perceptrons.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, K_x)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# K_x is the vector corresponding to the kernel evaluated at x against all X i.e. k(x, X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_training_pt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# perform cross-validation runs\n",
    "\n",
    "iterations = 20\n",
    "ds = list(range(1, 8))\n",
    "errs_cv = {}\n",
    "\n",
    "d_stars = []\n",
    "errs_test = []\n",
    "confusion_matrices = []\n",
    "for iteration in tqdm(list(range(iterations))):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)\n",
    "    \n",
    "    # perform cross validations\n",
    "    for d in ds:\n",
    "        errs_cv[d] = cross_validation_error(X_train, y_train, polynomial_kernel(d), epochs=10)\n",
    "        \n",
    "    # get best parameter\n",
    "    d_star = min(errs_cv, key=errs_cv.get)\n",
    "    d_stars.append(d_star)\n",
    "    \n",
    "    # get final error\n",
    "    results = basic_run(X_train, X_test, y_train, y_test, polynomial_kernel(d_star), epochs=20)\n",
    "    errs_test.append(results['err_test'])\n",
    "    \n",
    "    # compute confusion matrices too (so as to avoid recomputing in Q3)\n",
    "    confusion_matrices.append(confusion_error(X_test, y_test, results['model']))\n",
    "    \n",
    "# compute results   \n",
    "err_test_mean = np.mean(errs_test)\n",
    "d_star_mean = np.mean(d_stars)\n",
    "err_test_std = np.std(errs_test)\n",
    "d_star_std = np.std(d_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_stars</th>\n",
       "      <th>test_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    d_stars  test_errors\n",
       "0         4        0.050\n",
       "1         4        0.085\n",
       "2         5        0.070\n",
       "3         4        0.065\n",
       "4         5        0.055\n",
       "5         5        0.055\n",
       "6         6        0.095\n",
       "7         3        0.060\n",
       "8         4        0.075\n",
       "9         3        0.085\n",
       "10        7        0.100\n",
       "11        5        0.080\n",
       "12        6        0.080\n",
       "13        4        0.090\n",
       "14        3        0.075\n",
       "15        4        0.085\n",
       "16        3        0.080\n",
       "17        5        0.085\n",
       "18        3        0.095\n",
       "19        7        0.085"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display in dataframe\n",
    "cv_data = {'d_stars': d_stars, 'test_errors': errs_test}\n",
    "df = pd.DataFrame(data=cv_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_test</th>\n",
       "      <th>d_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.077500</td>\n",
       "      <td>4.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.013919</td>\n",
       "      <td>1.24499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      err_test   d_star\n",
       "mean  0.077500  4.50000\n",
       "std   0.013919  1.24499"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display in dataframe\n",
    "df_err = pd.DataFrame([[err_test_mean, err_test_std],\n",
    "                       [d_star_mean, d_star_std]], \n",
    "                       columns=['mean', 'std'], index=['err_test', 'd_star']).T\n",
    "print(\"Answer to 2:\")\n",
    "df_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Confusion Matrix\n",
    "\n",
    "We compute the confusion matrix for the above perceptron. (It's not clear to me here whether Mark means a confusion matrix for the training set or testing set. I think it makes sense to look at both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0          1          2          3          4          5  \\\n",
      "0   0.000000   0.000000  10.000000   0.000000  10.000000  35.000000   \n",
      "1   0.000000   0.000000   0.000000   0.000000   5.000000   0.000000   \n",
      "2   4.333333   2.500000   0.000000   7.500000  17.333333   5.833333   \n",
      "3   5.000000   2.500000  12.500000   0.000000   0.000000   6.666667   \n",
      "4  10.833333  13.214286  16.726190   0.000000   0.000000   2.083333   \n",
      "5  11.166667   0.000000   6.250000  16.916667  16.333333   0.000000   \n",
      "6  18.333333   8.333333  20.000000   0.000000   0.000000   6.666667   \n",
      "7   0.000000   8.750000   5.000000   0.000000  30.833333   0.000000   \n",
      "8  13.500000  10.750000   3.833333  11.428571   2.666667  14.845238   \n",
      "9   0.000000   9.166667   8.750000   0.000000  26.833333  11.833333   \n",
      "\n",
      "           6          7          8          9  \n",
      "0   0.000000   5.000000   0.000000   0.000000  \n",
      "1  25.000000   0.000000  10.000000   0.000000  \n",
      "2   8.333333   8.750000   2.916667   2.500000  \n",
      "3   0.000000   0.000000  46.666667   6.666667  \n",
      "4   0.714286  16.250000   5.000000  15.178571  \n",
      "5  13.083333   3.333333  15.666667   7.250000  \n",
      "6   0.000000   0.000000  16.666667   0.000000  \n",
      "7   0.000000   0.000000   0.000000  40.416667  \n",
      "8   4.380952  18.845238   0.000000   4.750000  \n",
      "9   0.000000  32.166667   6.250000   0.000000  \n",
      "           0          1          2          3          4          5  \\\n",
      "0   0.000000   0.000000  25.495098   0.000000  25.495098  42.130749   \n",
      "1   0.000000   0.000000   0.000000   0.000000  21.794495   0.000000   \n",
      "2  11.836854  10.897247   0.000000  23.848480  34.035929  21.905732   \n",
      "3  15.000000  10.897247  25.207472   0.000000   0.000000  16.158933   \n",
      "4  25.426911  25.457548  23.781159   0.000000   0.000000   6.387379   \n",
      "5  23.094612   0.000000  12.603736  26.427443  25.579940   0.000000   \n",
      "6  37.230513  23.273733  35.590261   0.000000   0.000000  22.607767   \n",
      "7   0.000000  24.076700  21.794495   0.000000  43.549142   0.000000   \n",
      "8  19.507121  24.913601   7.693793  19.182853   8.273116  15.239448   \n",
      "9   0.000000  18.615257  24.076700   0.000000  34.277868  23.528352   \n",
      "\n",
      "           6          7          8          9  \n",
      "0   0.000000  21.794495   0.000000   0.000000  \n",
      "1  43.301270   0.000000  30.000000   0.000000  \n",
      "2  23.863035  24.076700   8.848650  10.897247  \n",
      "3   0.000000   0.000000  40.688519  16.158933  \n",
      "4   3.113499  31.893377  21.794495  26.770829  \n",
      "5  24.823124  10.000000  25.643929  22.331312  \n",
      "6   0.000000   0.000000  35.746018   0.000000  \n",
      "7   0.000000   0.000000   0.000000  45.588360  \n",
      "8  11.250195  23.704922   0.000000  12.397076  \n",
      "9   0.000000  35.543791  22.185299   0.000000  \n"
     ]
    }
   ],
   "source": [
    "# display in dataframe\n",
    "confusion_matrix_array = np.array(confusion_matrices)\n",
    "confus_error_mean = np.mean(confusion_matrix_array, axis=0)\n",
    "confus_error_std = np.std(confusion_matrix_array, axis=0)\n",
    "\n",
    "df_cm_means = pd.DataFrame(confus_error_mean)\n",
    "print(df_cm_means)\n",
    "\n",
    "df_cm_std = pd.DataFrame(confus_error_std)\n",
    "print(df_cm_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hardest Predictions\n",
    "\n",
    "We define \"hardest to predict\" as: ... \n",
    "\n",
    "We then print out the five hardest to predict images, and discuss each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrain with our mean best d from cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 54.81it/s]\n"
     ]
    }
   ],
   "source": [
    "best_d = int(round(d_star_mean))\n",
    "model_hard_pred = VectorizedOneVsAllKernelPerceptron(X_train, y_train, polynomial_kernel(best_d))\n",
    "model_hard_pred.train_for_epochs(10, progress=True)\n",
    "magns = model_hard_pred.predict_mag(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_two_vals_diff(X):\n",
    "    large1 = np.min(X)\n",
    "    large2 = np.min(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        if X[i] > large1:\n",
    "            large1 = X[i]\n",
    "        elif X[i] > large2:\n",
    "            large2 = X[i]\n",
    "    diff = large1 - large2\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_diff(magnitudes):    \n",
    "    five_diffs = np.zeros(5)\n",
    "    five_id = np.zeros(5)\n",
    "    for j in range(five_diffs.shape[0]):\n",
    "        five_diffs[j] = largest_two_vals_diff(magns[:, 0])\n",
    "        five_id[j] = 0\n",
    "        for i in range(magnitudes.shape[1]):\n",
    "            temp = largest_two_vals_diff(magnitudes[:, i])\n",
    "            if temp < five_diffs[j]:\n",
    "                five_diffs[j] = temp\n",
    "                five_id[j] = i\n",
    "        magnitudes = np.delete(magnitudes, five_id[j], 1)\n",
    "    return five_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliver Slumbers\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corresponding labels are: 6\n",
      "The corresponding labels are: 3\n",
      "The corresponding labels are: 8\n",
      "The corresponding labels are: 5\n",
      "The corresponding labels are: 7\n"
     ]
    }
   ],
   "source": [
    "diff_id = five_diff(magns)\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 5\n",
    "rows = 1\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(X_test[int(diff_id[i-1])].reshape(16,16), cmap='gray')\n",
    "plt.show()\n",
    "for i in list(diff_id):\n",
    "    print(\"The corresponding labels are: {}\".format(y_test[int(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(magnitudes):\n",
    "    min_vals = np.min(magnitudes, axis=0)\n",
    "    max_vals = np.max(magnitudes, axis=0)\n",
    "    new_mags = (magnitudes - min_vals) / (max_vals - min_vals)\n",
    "    return (new_mags/new_mags.sum(axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_entropies(magnitudes):    \n",
    "    five_ent = np.zeros(5)\n",
    "    five_id = np.zeros(5)\n",
    "    norm_mags = normalise(magnitudes)\n",
    "    entropies = entropy(norm_mags)\n",
    "    for j in range(five_ent.shape[0]):\n",
    "        five_ent[j] = np.max(entropies)\n",
    "        five_id[j] = np.argmax(entropies)\n",
    "        entropies = np.delete(entropies, five_id[j], 0)\n",
    "    return five_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliver Slumbers\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corresponding labels are: 1\n",
      "The corresponding labels are: 5\n",
      "The corresponding labels are: 5\n",
      "The corresponding labels are: 2\n",
      "The corresponding labels are: 5\n"
     ]
    }
   ],
   "source": [
    "ent_id = five_entropies(magns)\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 5\n",
    "rows = 1\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(X_test[int(ent_id[i-1])].reshape(16,16), cmap='gray')\n",
    "plt.show()\n",
    "for i in list(ent_id):\n",
    "    print(\"The corresponding labels are: {}\".format(y_test[int(i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat 1 with a gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# perform basic runs\n",
    "iterations = 20\n",
    "width_list = np.arange(0.01, 0.1, 0.01)\n",
    "err_train = {g: [] for g in width_list}\n",
    "err_test = {g: [] for g in width_list}\n",
    "\n",
    "for iteration in tqdm(list(range(iterations))):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)\n",
    "    \n",
    "    for g in width_list:\n",
    "        #split data\n",
    "        results = basic_run(X_train, X_test, y_train, y_test, gaussian_kernel_2(g), 5)\n",
    "        err_train[g].append(results['err_train'])\n",
    "        err_test[g].append(results['err_test'])\n",
    "    \n",
    "err_train_mean = {g: np.mean(errs) for g, errs in err_train.items()}\n",
    "err_test_mean = {g: np.mean(errs) for g, errs in err_test.items()}\n",
    "err_train_std = {g: np.std(errs) for g, errs in err_train.items()}\n",
    "err_test_std = {g: np.std(errs) for g, errs in err_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.08500</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.015969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.08325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.07</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.12450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.12475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.09</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.13550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_mean  test_mean  train_std  test_std\n",
       "0.01    0.000187    0.08500   0.000596  0.015969\n",
       "0.02    0.000000    0.08325   0.000000  0.016679\n",
       "0.03    0.000000    0.09650   0.000000  0.015580\n",
       "0.04    0.000000    0.11200   0.000000  0.023206\n",
       "0.05    0.000000    0.12050   0.000000  0.021789\n",
       "0.06    0.000000    0.11575   0.000000  0.021464\n",
       "0.07    0.000000    0.12450   0.000000  0.022187\n",
       "0.08    0.000000    0.12475   0.000000  0.019201\n",
       "0.09    0.000000    0.13550   0.000000  0.023179"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display in dataframe\n",
    "df_err = pd.DataFrame([err_train_mean, err_test_mean,\n",
    "                       err_train_std, err_test_std], \n",
    "                       index=['train_mean', 'test_mean', 'train_std', 'test_std'], \n",
    "                       columns=width_list).T\n",
    "df_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat 2 with a gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:21<00:00,  4.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# perform cross-validation runs\n",
    "\n",
    "iterations = 20\n",
    "width_list = np.arange(0.005, 0.105, 0.01)\n",
    "errs_cv = {}\n",
    "\n",
    "sigma_stars = []\n",
    "errs_test = []\n",
    "confusion_matrices = []\n",
    "for iteration in tqdm(list(range(iterations))):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)\n",
    "    \n",
    "    # perform cross validations\n",
    "    for g in width_list:\n",
    "        errs_cv[g] = cross_validation_error(X_train, y_train, gaussian_kernel_2(g))\n",
    "        \n",
    "    # get best parameter\n",
    "    sigma_star = min(errs_cv, key=errs_cv.get)\n",
    "    sigma_stars.append(sigma_star)\n",
    "    \n",
    "    # get final error\n",
    "    results = basic_run(X_train, X_test, y_train, y_test, gaussian_kernel_2(sigma_star))\n",
    "    errs_test.append(results['err_test'])\n",
    "    \n",
    "    # compute confusion matrices too (so as to avoid recomputing in Q3)\n",
    "    confusion_matrices.append(confusion_error(X_test, y_test, results['model']))\n",
    "    \n",
    "# compute results   \n",
    "err_test_mean = np.mean(errs_test)\n",
    "sigma_star_mean = np.mean(sigma_stars)\n",
    "err_test_std = np.std(errs_test)\n",
    "sigma_star_std = np.std(sigma_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigma_stars</th>\n",
       "      <th>test_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sigma_stars  test_errors\n",
       "0         0.015        0.075\n",
       "1         0.015        0.075\n",
       "2         0.015        0.080\n",
       "3         0.015        0.080\n",
       "4         0.015        0.090\n",
       "5         0.025        0.070\n",
       "6         0.015        0.070\n",
       "7         0.015        0.085\n",
       "8         0.015        0.080\n",
       "9         0.015        0.085\n",
       "10        0.015        0.070\n",
       "11        0.015        0.070\n",
       "12        0.015        0.105\n",
       "13        0.025        0.100\n",
       "14        0.015        0.055\n",
       "15        0.015        0.065\n",
       "16        0.015        0.095\n",
       "17        0.015        0.085\n",
       "18        0.015        0.070\n",
       "19        0.015        0.095"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display in dataframe\n",
    "cv_data = {'sigma_stars': sigma_stars, 'test_errors': errs_test}\n",
    "df = pd.DataFrame(data=cv_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_test</th>\n",
       "      <th>d_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012349</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      err_test  d_star\n",
       "mean  0.080000   0.016\n",
       "std   0.012349   0.003"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display in dataframe\n",
    "df_err = pd.DataFrame([[err_test_mean, err_test_std],\n",
    "                       [sigma_star_mean, sigma_star_std]], \n",
    "                       columns=['mean', 'std'], index=['err_test', 'd_star']).T\n",
    "print(\"Answer to 2:\")\n",
    "df_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Basic Results: Perform 20 runs for d = 1, . . . , 7 each run should randomly split zipcombo into 80%\n",
    "train and 20% test. Report the mean test and train errors as well as well as standard deviations.\n",
    "Thus your data table, here, will be 2 × 7 with each “cell” containing a mean±std.\n",
    "2. Cross-validation: Perform 20 runs : when using the 80% training data split from within to perform\n",
    "5-fold cross-validation to select the “best” parameter d\n",
    "∗\n",
    "then retrain on full 80% training set using\n",
    "d\n",
    "∗ and then record the test errors on the remaining 20%. Thus you will find 20 d\n",
    "∗ and 20 test errors.\n",
    "Your final result will consist of a mean test error±std and a mean d\n",
    "∗ with std.\n",
    "3. Confusion matrix: Perform 20 runs : when using the 80% training data split that further to perform\n",
    "5-fold cross-validation to select the “best” parameter d\n",
    "∗\n",
    "retrain on the 80% training using d\n",
    "∗ and\n",
    "produce a confusion matrix. Here the goal is to find “confusions” thus if the true label was “7” and\n",
    "“2” was predicted then a “mistake” should recorded for “(7,2)”; the final output will be a 10 × 10\n",
    "matrix where each cell contains a confusion error and its standard deviation. Note the diagonal will\n",
    "be 0.\n",
    "4. Within the dataset relative to your experiments there will be five hardest to predict correctly “data\n",
    "items.” Print out the visualisation of these five digits along with their labels. Is it surprising that\n",
    "these are hard to predict?\n",
    "5. Repeat 1 and 2 (d\n",
    "∗\n",
    "is now c and {1, . . . , 7} is now S) above with a Gaussian kernel\n",
    "K(p, q) = e\n",
    "−ckp−qk\n",
    "2\n",
    ",\n",
    "c the width of the kernel is now a parameter which must be optimised during cross-validation however,\n",
    "you will also need to perform some initial experiments to a decide a reasonable set S of values to crossvalidate c over.\n",
    "6. Choose (research) an alternate method to generalise to k-classes then repeat 1 and 2.\n",
    "7. Choose two more algorithms to compare to the kernel perceptron each of these algorithms will have\n",
    "a parameter vector θ and you will need to determine a cross-validation set Sθ with this information\n",
    "repeat 1 and 2 for your new algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
